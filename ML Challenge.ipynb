{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport time\nfrom numpy import sqrt\nfrom numpy import argmax\n\n# Handle missing values\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.utils import resample\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.over_sampling import ADASYN \n\n# Data scaling\nfrom sklearn import preprocessing\n\n# Split data\nfrom sklearn.model_selection import train_test_split\n\n# Classifiers\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingRegressor, BaggingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.neural_network import MLPClassifier\nfrom xgboost import XGBRegressor\nimport catboost\nfrom catboost import CatBoostRegressor\n\n# Feature selection\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\n\n# Hyperparameter tuning\nfrom imblearn.pipeline import Pipeline\nfrom sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\nfrom scipy import stats\n\n# Analysis\nfrom sklearn import metrics\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nfrom sklearn.metrics import classification_report\n\n# Visualisation\nimport seaborn as sb\nfrom pandas.plotting import scatter_matrix\nfrom matplotlib.colors import ListedColormap\nimport matplotlib.pyplot as plt\nfrom matplotlib.legend_handler import HandlerLine2D","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read train and test datasets\n\nall_features = pd.Series([\n    'age', 'class of worker', 'detailed industry code', 'detailed occupation code', 'education', 'wage per hour', 'enroll in edu inst last wk',\n    'marital status', 'major industry', 'major occupation', 'race', 'hispanic origin', 'sex', 'member of a labor union',\n    'reason for unemployment', 'full or part time employment stat', 'capital gains', 'capital losses', 'dividends from stocks',\n    'tax filer stat', 'region of previous residence', 'state of previous residence', 'detailed household and family stat',\n    'detailed household summary in household', 'instance weight', 'migration code-change in msa', 'migration code-change in reg',\n    'migration code-move within reg', 'lived in this house 1 year ago', 'migration prev res in sunbelt', 'num persons worked for employer',\n    'family members under 18', 'country of birth father', 'country of birth mother', 'country of birth self', 'citizenship',\n    'own business or self employed', 'fill inc questionnaire for veterans admin', 'veterans benefits', 'weeks worked in year',\n    'year', 'income class'\n])\n\n# Read training and test datasets\ntrain_data_unprocessed = pd.read_csv('/kaggle/input/ml-challenge-week6/census-income.data', names=all_features, sep=' *, *', na_values='?', engine='python')\ntest_data_unprocessed = pd.read_csv('/kaggle/input/ml-challenge-week6/census-income.test', names=all_features, sep=' *, *', na_values='?', engine='python')\nassert len(all_features) == len(train_data_unprocessed.columns) == len(test_data_unprocessed.columns), 'Invalid number of columns'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Handle missing data\n# https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779\n# Columns with missing values: 'class of worker', 'enroll in edu inst last wk', 'major occupation', 'hispanic origin', 'member of a labor union', \n# 'reason for unemployment', 'region of previous residence', 'state of previous residence', 'migration code-change in msa', 'migration code-change in reg', \n# 'migration code-move within reg', 'migration prev res in sunbelt', 'family members under 18', 'country of birth father', 'country of birth mother', \n# 'country of birth self', 'fill inc questionnaire for veterans admin'\ntrain_data_no_missing_data = train_data_unprocessed.copy()\ntest_data_no_missing_data = test_data_unprocessed.copy()\n\n# Optional - Replace 'Not in universe'\ntrain_data_no_missing_data = train_data_no_missing_data.replace('Not in universe', np.nan)\ntest_data_no_missing_data = test_data_no_missing_data.replace('Not in universe', np.nan)\n\ntrain_data_no_missing_data.replace('?', np.nan, inplace=True)\nassert train_data_no_missing_data.where(train_data_no_missing_data == '?').any().sum() == 0, \"Unexpected value in dataset\"\nassert test_data_no_missing_data.where(test_data_no_missing_data == '?').any().sum() == 0, \"Unexpected value in dataset\"\n\n# Optional - remove columns with missing data above threashold\n# Note: columns with missing data are removed further down\n# train_data_no_missing_data = train_data_no_missing_data.loc[:, train_data_no_missing_data.isnull().mean() < .001]\n# test_data_no_missing_data = test_data_no_missing_data.loc[:, test_data_no_missing_data.isnull().mean() < .001]\n\n# Fill missing values\ntrain_data_no_missing_data = train_data_no_missing_data.fillna(\"Unknown\")\ntest_data_no_missing_data = test_data_no_missing_data.fillna(\"Unknown\")\nassert train_data_no_missing_data.isnull().values.sum() == 0, \"Training dataset should not have any nan values\"\nassert test_data_no_missing_data.isnull().values.sum() == 0, \"Test dataset should not have any nan values\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop duplicates - training dataset only\n# Number of instances data = 199523, Duplicate or conflicting instances : 46716\n# Number of instances in test = 99762, Duplicate or conflicting instances : 20936\n# Note: For this challenge, the test dataset must not be altered\nnr_train_data_before = train_data_no_missing_data.shape\ntrain_data_no_duplicates = train_data_no_missing_data.drop_duplicates(keep=False, inplace=False)\ntest_data_no_duplicates = test_data_no_missing_data\nprint(\"Duplicate training dataset rows removed: \", nr_train_data_before[0] - train_data_no_duplicates.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Selection\n# MSA: https://en.wikipedia.org/wiki/List_of_metropolitan_statistical_areas\n\n# Option 1: Features opt-out\nfeatures_to_drop = [\n \n    # ====== Missing data cleanup ======\n    \n    # Feature clenaup > 70% missing data\n    \n    'family members under 18', # Diff: 0.08\n    'fill inc questionnaire for veterans admin',\n    'enroll in edu inst last wk', # Diff: 0.05\n    'migration prev res in sunbelt',\n    'region of previous residence', 'state of previous residence',\n    'member of a labor union', # Diff: 0.02\n    \n    # Feature cleanup > 50% missing data\n    \n    'major occupation', # Diff: 0.21\n    'migration code-change in reg',\n    'migration code-move within reg',\n    \n     # Feature cleanup 0.001% < missing data % < 0.1%\n    \n    'country of birth self', 'country of birth mother', 'country of birth father',\n    'hispanic origin', # Diff: 0.04\n\n    # ====== High predictive power ======\n    \n#     'class of worker', # Diff: 0.25\n    \n#     'education' Diff: 0.21\n    \n    # Occupation & industry: \n    'major industry', \n#     'detailed occupation code', 'detailed industry code',\n    \n#     'dividends from stocks', # Diff: 0.21\n    \n#     #  Business owner: Diff: 0.15\n    'own business or self employed',\n    \n#     # 'age' Diff: 0.12\n\n#     # Status: \n#      'marital status', # Diff: 0.10\n    'detailed household summary in household', # Diff: 0.10\n#     'tax filer stat', # Diff: 0.06\n    'detailed household and family stat',\n    \n#     # ====== Medium predictive power ======\n            \n#     # Employment\n#     'reason for unemployment',\n    'full or part time employment stat', # Diff: 0.08\n            \n#     # Veteran\n#     'veterans benefits', # Diff: 0.08\n                      \n#     'race', 'sex', # Diff: 0.06\n        \n#     # ====== Low predictive power ======\n        \n#     # Citizenship: \n#     'citizenship', # Diff: 0.04\n        \n#     # Has moved: \n#     'migration code-change in msa', 'lived in this house 1 year ago', # Diff: 0.03\n            \n    # ====== Other features ======\n    \n    # wage per hour, weeks worked in year\n    \n    # Not relevant\n    'year'\n]\n\n# Option 2: Features opt-in\n# feature_to_use = [\n#     'age', 'class of worker', 'education', 'marital status', 'major occupation', 'race', 'sex',\n#     'capital gains', 'capital losses', 'wage per hour', 'weeks worked in year', 'citizenship'\n# ]\n# features_to_drop = [x for x in all_features if x not in feature_to_use]\n\ntrain_data_selected = train_data_no_duplicates.copy()\ntest_data_selected = test_data_no_duplicates.copy()\n\nselected_features = [x for x in all_features if x not in features_to_drop]\nprint(\"Nr of selected features:\", len(selected_features))\ntrain_data_selected = train_data_selected.drop(features_to_drop, axis=1)\ntest_data_selected = test_data_selected.drop(features_to_drop, axis=1)\nassert len(selected_features) == len(train_data_selected.columns) == len(test_data_selected.columns), 'Unexpected number of features'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature engineering\nX_train_engineered = train_data_selected.copy()\ntest_data_engineered = test_data_selected.copy() \nengineered_features = selected_features.copy()\n\n# ============ Collapse states ============ \n\n# Collapse age and remove minors - very slightly decreases performance\n# X_train_engineered['age'] = X_train_engineered['age'].div(10).round()\n# test_data_engineered['age'] = test_data_engineered['age'].div(10).round()\n\n# Collapse marrital status\nprint(\"Marrital status:\", set(X_train_engineered[\"marital status\"]))\nmarrital_status_single = ['Never married', 'Separated', 'Divorced', 'Widowed']\nmarrital_status_married = ['Married-civilian spouse present', 'Married-spouse absent', 'Married-A F spouse present']\nX_train_engineered[\"marital status\"] = X_train_engineered[\"marital status\"].replace(marrital_status_single, 'Single')\ntest_data_engineered[\"marital status\"] = test_data_engineered[\"marital status\"].replace(marrital_status_single, 'Single')\nX_train_engineered[\"marital status\"] = X_train_engineered[\"marital status\"].replace(marrital_status_married, 'Married')\ntest_data_engineered[\"marital status\"] = test_data_engineered[\"marital status\"].replace(marrital_status_married, 'Married')\nprint(\"Updated marrital status:\", set(X_train_engineered[\"marital status\"]))\n\n# Citizenship: US vs non-US - degrades performance\n# us_citizen = ['Foreign born- U S citizen by naturalization', 'Native- Born abroad of American Parent(s)', 'Native- Born in the United States']\n# non_us_citizen = ['Foreign born- Not a citizen of U S', 'Native- Born in Puerto Rico or U S Outlying']\n# X_train_engineered[\"citizenship\"] = X_train_engineered[\"citizenship\"].replace(non_us_citizen, 0)\n# X_train_engineered[\"citizenship\"] = X_train_engineered[\"citizenship\"].replace(us_citizen, 1)\n# test_data_engineered[\"citizenship\"] = test_data_engineered[\"citizenship\"].replace(non_us_citizen, 0)\n# test_data_engineered[\"citizenship\"] = test_data_engineered[\"citizenship\"].replace(us_citizen, 1)\n# print(\"\\nCitizenship:\")\n# print(test_data_engineered['citizenship'].value_counts())\n\n# Country of birth self - degrades performance\n# X_train_engineered.loc[~X_train_engineered[\"country of birth self\"].isin(['United-States']), \"country of birth self\"] = 0\n# X_train_engineered.loc[X_train_engineered[\"country of birth self\"].isin(['United-States']), \"country of birth self\"] = 1\n# test_data_engineered.loc[~test_data_engineered[\"country of birth self\"].isin(['United-States']), \"country of birth self\"] = 0\n# test_data_engineered.loc[test_data_engineered[\"country of birth self\"].isin(['United-States']), \"country of birth self\"] = 1\n# print(\"\\nCountry of birth self:\")\n# print(test_data_engineered['country of birth self'].value_counts())\n\n# Collapse wage per hour - cents to dollars - degrades performance\n# X_train_engineered['wage per hour'] = X_train_engineered['wage per hour'].div(100).round()\n# test_data_engineered['wage per hour'] = test_data_engineered['wage per hour'].div(100).round()\n\n# Collapse major occupation - degrades performance\n# techinal_jobs = ['Craft-repair','Precision production craft & repair','Machine operators assmblrs & inspctrs']\n# service_jobs = ['Other service','Private household services','Protective services','Sales']\n# support_jobs = ['Adm support including clerical','Technicians and related support']\n# high_level_jobs = ['Executive admin and managerial','Professional specialty']\n# low_level_jobs = ['Farming forestry and fishing','Armed Forces','Handlers equip cleaners etc','Transportation and material moving']\n# X_train_engineered[\"major occupation\"] = X_train_engineered[\"major occupation\"].replace(techinal_jobs, 'Technical')\n# X_train_engineered[\"major occupation\"] = X_train_engineered[\"major occupation\"].replace(service_jobs, 'Service')\n# X_train_engineered[\"major occupation\"] = X_train_engineered[\"major occupation\"].replace(support_jobs, 'Support')\n# X_train_engineered[\"major occupation\"] = X_train_engineered[\"major occupation\"].replace(high_level_jobs, 'High-level')\n# X_train_engineered[\"major occupation\"] = X_train_engineered[\"major occupation\"].replace(low_level_jobs, 'Low-level')\n# test_data_engineered[\"major occupation\"] = test_data_engineered[\"major occupation\"].replace(techinal_jobs, 'Technical')\n# test_data_engineered[\"major occupation\"] = test_data_engineered[\"major occupation\"].replace(service_jobs, 'Service')\n# test_data_engineered[\"major occupation\"] = test_data_engineered[\"major occupation\"].replace(support_jobs, 'Support')\n# test_data_engineered[\"major occupation\"] = test_data_engineered[\"major occupation\"].replace(high_level_jobs, 'High-level')\n# test_data_engineered[\"major occupation\"] = test_data_engineered[\"major occupation\"].replace(low_level_jobs, 'Low-level')\n# print(\"\\nHigh level job:\")\n# print(test_data_engineered['major occupation'].value_counts())\n\n# Household summary: Householder vs non-householder\n# X_train_engineered.loc[~X_train_engineered[\"detailed household summary in household\"].isin(['Householder']), \"detailed household summary in household\"] = 0\n# X_train_engineered.loc[X_train_engineered[\"detailed household summary in household\"].isin(['Householder']), \"detailed household summary in household\"] = 1\n# test_data_engineered.loc[~test_data_engineered[\"detailed household summary in household\"].isin(['Householder']), \"detailed household summary in household\"] = 0\n# test_data_engineered.loc[test_data_engineered[\"detailed household summary in household\"].isin(['Householder']), \"detailed household summary in household\"] = 1\n# print(\"\\nHousehold summary:\")\n# print(test_data_engineered['detailed household summary in household'].value_counts())\n\n# Collapse dividends from stocks\n# X_train_engineered.loc[X_train_engineered[\"dividends from stocks\"] > 0, \"dividends from stocks\"] = 1\n# test_data_engineered.loc[test_data_engineered[\"dividends from stocks\"] > 0, \"dividends from stocks\"] = 1\n# print(\"\\nDividents from stocks:\")\n# print(\"No dividents:\",len(test_data_engineered[test_data_engineered['dividends from stocks'] == 0]))\n# print(\"Dividents:\",len(test_data_engineered[test_data_engineered['dividends from stocks'] > 0]))\n\n# ============ Add features ============ \n\n# Addd 'is highly educated'\nengineered_features = np.concatenate([engineered_features, ['is highly educated']])\nis_highly_educated = ['Associates degree-academic program', 'Associates degree-occup /vocational', 'Bachelors degree(BA AB BS)', 'Doctorate degree(PhD EdD)',\n                      'High school graduate', 'Masters degree(MA MS MEng MEd MSW MBA)', 'Prof school degree (MD DDS DVM LLB JD)', 'Some college but no degree']\n# is_highly_educated = ['Bachelors degree(BA AB BS)', 'Doctorate degree(PhD EdD)', 'Masters degree(MA MS MEng MEd MSW MBA)', 'Prof school degree (MD DDS DVM LLB JD)']\nX_train_engineered.loc[~X_train_engineered[\"education\"].isin(is_highly_educated), \"is highly educated\"] = 0\nX_train_engineered.loc[X_train_engineered[\"education\"].isin(is_highly_educated), \"is highly educated\"] = 1\ntest_data_engineered.loc[~test_data_engineered[\"education\"].isin(is_highly_educated), \"is highly educated\"] = 0\ntest_data_engineered.loc[test_data_engineered[\"education\"].isin(is_highly_educated), \"is highly educated\"] = 1\nprint(\"\\nEducation:\")\nprint(test_data_engineered['is highly educated'].value_counts())\n\n# No salary - degrades performance\n# engineered_features = np.concatenate([engineered_features, ['no salary']])\n# X_train_engineered.loc[X_train_engineered[\"class of worker\"].isin(['Never worked', 'Without pay']), \"no salary\"] = 1\n# X_train_engineered.loc[~X_train_engineered[\"class of worker\"].isin(['Never worked', 'Without pay']), \"no salary\"] = 0\n# test_data_engineered.loc[test_data_engineered[\"class of worker\"].isin(['Never worked', 'Without pay']), \"no salary\"] = 1\n# test_data_engineered.loc[~test_data_engineered[\"class of worker\"].isin(['Never worked', 'Without pay']), \"no salary\"] = 0\n# print(\"\\nNo salary:\")\n# print(test_data_engineered['no salary'].value_counts())\n\n# Both monthly wage and weeks worked in year are available, but the data is incomplete\n# engineered_features = np.concatenate([engineered_features, ['yearly income']])\n# X_train_engineered['yearly income'] = (X_train_engineered['wage per hour'] * X_train_engineered['weeks worked in year']).multiply(8).multiply(5).div(10000).round()\n# test_data_engineered['yearly income'] = (test_data_engineered['wage per hour'] * test_data_engineered['weeks worked in year']).multiply(8).multiply(5).div(10000).round()\n# X_train_engineered.loc[X_train_engineered[\"yearly income\"].between(0, 5, inclusive=False), \"yearly income\"] = 1\n# X_train_engineered.loc[X_train_engineered[\"yearly income\"] >= 5, \"yearly income\"] = 2\n# test_data_engineered.loc[test_data_engineered[\"yearly income\"].between(0, 5, inclusive=False), \"yearly income\"] = 1\n# test_data_engineered.loc[test_data_engineered[\"yearly income\"] >= 5, \"yearly income\"] = 2\n# print(\"\\nYearly income:\")\n# print(test_data_engineered['yearly income'].value_counts())\n                                          \n# Merge capital gains and capital loss fields, they are exclusive\nassert len(X_train_engineered[(X_train_engineered['capital gains'] != 0) & (X_train_engineered['capital losses'] != 0)]) == 0, \"Expecting no entries with both capital gains and capital losses\"\nengineered_features = np.concatenate([engineered_features, ['capital gains loss']])\nX_train_engineered['capital gains loss'] = X_train_engineered['capital gains'] - X_train_engineered['capital losses']\ntest_data_engineered['capital gains loss'] = test_data_engineered['capital gains'] - test_data_engineered['capital losses']\n\nfeatures_to_drop = [ \n    'capital gains', 'capital losses',\n#     'major occupation',\n#     'country of birth self',\n#     'wage per hour', 'weeks worked in year'\n#     'class of worker',\n]\nengineered_features = [x for x in engineered_features if x not in features_to_drop]\nX_train_engineered = X_train_engineered.drop(features_to_drop, axis=1)\ntest_data_engineered = test_data_engineered.drop(features_to_drop, axis=1)\nprint(\"\\nEngineered features:\", len(engineered_features))\nassert len(engineered_features) == len(X_train_engineered.columns) == len(test_data_engineered.columns), 'Unexpected number of features'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encode categories\n# https://towardsdatascience.com/encoding-categorical-features-21a2651a065c\n# https://towardsdatascience.com/categorical-encoding-using-label-encoding-and-one-hot-encoder-911ef77fb5bd\n\nencoder = preprocessing.LabelEncoder()\nX_train_encoded = X_train_engineered.copy()\ntest_data_encoded = test_data_engineered.copy()\ncombined_data = pd.concat([X_train_encoded, test_data_encoded]) # The encoder should be fitted using both train and test datasets.\n\nX_train_encoded['income class'] = X_train_encoded['income class'].map({'- 50000.': 0, '50000+.': 1})\n\nlabel_encoding = { }\nfor feature in engineered_features:      \n    if X_train_encoded[feature].dtype == \"object\":\n        encoder.fit(combined_data[feature].astype(str))\n        X_train_encoded[feature] = encoder.transform(X_train_encoded[feature].astype(str))\n        label_encoding[feature] = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n    if test_data_encoded[feature].dtype == \"object\":\n        encoder.fit(combined_data[feature].astype(str))\n        test_data_encoded[feature] = encoder.transform(test_data_encoded[feature].astype(str))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualise correlations between features and income class\n\n# Veteran benefits\n# g = sb.factorplot(x=\"veterans benefits\", y=\"income class\", data=X_train_encoded, kind=\"bar\", height = 10, palette = \"muted\")\n# g.despine(left=True)\n# g = g.set_ylabels(\"Income >50K Probability\")\n# plt.show()\n\n# enroll in edu inst last wk\n# g = sb.factorplot(x=\"enroll in edu inst last wk\", y=\"income class\", data=X_train_encoded, kind=\"bar\", height = 10, palette = \"muted\")\n# g.despine(left=True)\n# g = g.set_ylabels(\"Income >50K Probability\")\n# plt.show()\n\n# Has moved: lived in this house 1 year ago\n# print(label_encoding['lived in this house 1 year ago'])\n# g = sb.factorplot(x=\"lived in this house 1 year ago\", y=\"income class\", data=X_train_encoded, kind=\"bar\", height = 10, palette = \"muted\")\n# g.despine(left=True)\n# g = g.set_ylabels(\"Income >50K Probability\")\n# plt.show()\n\n# 'detailed household summary in household',\n# print(label_encoding['detailed household summary in household'])\n# g = sb.factorplot(x=\"detailed household summary in household\", y=\"income class\", data=X_train_encoded, kind=\"bar\", height = 10, palette = \"muted\")\n# g.despine(left=True)\n# g = g.set_ylabels(\"Income >50K Probability\")\n# plt.show()\n\n# Citizenship\n# g = sb.factorplot(x=\"citizenship\", y=\"income class\", data=X_train_encoded, kind=\"bar\", height = 10, palette = \"muted\")\n# g.despine(left=True)\n# g = g.set_ylabels(\"Income >50K Probability\")\n# plt.show()\n\n# Major occupation\n# print(label_encoding['major occupation'])\n# g = sb.factorplot(x=\"major occupation\", y=\"income class\", data=X_train_encoded, kind=\"bar\", height = 10, palette = \"muted\")\n# g.despine(left=True)\n# g = g.set_ylabels(\"Income >50K Probability\")\n# plt.show()\n\n# Class of worker\n# print(label_encoding['class of worker'])\n# X_train_encoded.groupby([\"income class\", \"class of worker\"]).size().unstack(\"income class\").plot(kind=\"bar\",fontsize=14, figsize=(10,10))\n\n# print(label_encoding['education'])\n# X_train_encoded[['education','income class']].groupby(['education']).mean()\n\n# Explore Education vs Income\n# print(label_encoding['education'])\n# g = sb.factorplot(x=\"education\", y=\"income class\", data=X_train_encoded, kind=\"bar\", height = 10, palette = \"muted\")\n# g.despine(left=True)\n# g = g.set_ylabels(\">50K probability\")\n\n# # Explore Age vs Income\n# g = sb.FacetGrid(X_train_encoded, col='income class', height=10)\n# g = g.map(sb.distplot, \"age\")\n# plt.show()\n\n# # Explore detailed household summary in household vs Income\n# print(label_encoding['tax filer stat'])\n# g = sb.factorplot(x=\"tax filer stat\", y=\"income class\", data=X_train_encoded, kind=\"bar\", height = 10, palette = \"muted\")\n# g.despine(left=True)\n# g = g.set_ylabels(\"Income >50K Probability\")\n# plt.show()\n\n# Explore wage per hour\n# g = sb.factorplot(x=\"wage per hour\", y=\"income class\", data=X_train_encoded, kind=\"bar\", height = 15, palette = \"muted\")\n# g.despine(left=True)\n# g = g.set_ylabels(\"Income >50K Probability\")\n# plt.show()\n\n# # Explore Marital Status vs Income\n# print(label_encoding['marital status'])\n# g = sb.factorplot(x=\"marital status\", y=\"income class\", data=X_train_encoded, kind=\"bar\", height = 10, palette = \"muted\")\n# g.despine(left=True)\n# g = g.set_ylabels(\"Income >50K Probability\")\n# plt.show()\n\n# Explore class of worker vs Income\n# print(label_encoding['class of worker'])\n# g = sb.factorplot(x=\"class of worker\", y=\"income class\", data=X_train_encoded, kind=\"bar\", height = 6, palette = \"muted\")\n# g.despine(left=True)\n# g = g.set_ylabels(\"Income >50K Probability\")\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare training and test datasets\n# 'income class' should be used for validation, not for classification\n# Note: This cannot be done before duplicate entries are removed\ntrain_data = X_train_encoded.copy()\ntest_data = test_data_encoded.copy()\ny = train_data['income class']\n\nfeatures = [x for x in engineered_features if x not in ['income class']]\ntrain_data = train_data.drop(['income class'], axis=1)\ntest_data = test_data.drop(['income class'], axis=1)\nassert len(features) == len(train_data.columns) == len(test_data.columns), \"Unexpected number of features\"\n\n# Split training dataset\n# Stratify: training and test datasets are in the same proportion as the whole dataset\nX_train, X_validation, y_train, y_validation = train_test_split(train_data, y, test_size=0.2, stratify=y, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Handling unbalanced datasets\n\nX_train = X_train.copy()\ny_train = y_train.copy()\n\n# Option 1: Upsample minority\n# negative = train_data[train_data['income class'] == 0]\n# positive = train_data[train_data['income class'] == 1]\n# pos_upsampled = resample(positive,\n#                          replace=True,\n#                          n_samples=len(negative), # match number in majority class\n#                          random_state=42)\n# train_data = pd.concat([negative, pos_upsampled])\n# print(train_data['income class'].value_counts())\n\n# Option 2: Downsample majority\n# negative = train_data[train_data['income class'] == 0]\n# positive = train_data[train_data['income class'] == 1]\n# neg_downsampled = resample(negative, \n#                            replace=False,            \n#                            n_samples=len(positive),  # match number in minority class\n#                            random_state=42)          \n# train_data = pd.concat([positive, neg_downsampled])\n# print(train_data['income class'].value_counts())\n\n# Option 3: SMOTE\n# sm = SMOTE(random_state = 42)\n# X_train, y_train = sm.fit_sample(X_train, y_train.ravel())\n\n# Option 4: SMOTE & RandomUnderSampler\n# sm = SMOTE(sampling_strategy=0.1, random_state=42)\n# X_train, y_train = sm.fit_sample(X_train, y_train)\n# over = SMOTE(sampling_strategy=0.1)\n# from imblearn.under_sampling import RandomUnderSampler\n# under = RandomUnderSampler(random_state=42)\n# steps = [('o', over), ('u', under)]\n# pipeline = Pipeline(steps=steps)\n# X_train, y_train = pipeline.fit_resample(X_train, y_train)\n\n# Option 5: ADASYN\n# adasym = ADASYN(random_state=42)\n# X_train, y_train = adasym.fit_sample(X_train, y_train)\n\n# # Option 6: SMOTETomek\n# from imblearn.combine import SMOTETomek\n# smt = SMOTETomek()\n# X_train, y_train = smt.fit_sample(X_train, y_train)\n\n# 'sample weight' should be as input when training the models, but not as a feature\nsample_weight_train = X_train['instance weight']\nsample_weight_validation = X_validation['instance weight']\nassert len(sample_weight_train) == len(X_train), \"Nr of sample weights does not match the nr of samples\"\n\nfeatures = [x for x in features if x not in ['instance weight']]\nX_train = X_train.drop(['instance weight'], axis=1)\nX_validation = X_validation.drop(['instance weight'], axis=1)\ntest_data = test_data.drop(['instance weight'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # PCA\n\ndef compute_scores(X):\n    pca = PCA(svd_solver='full')\n    pca_scores = []\n    for n in np.arange(1, len(features), 1):\n        pca.n_components = n\n        pca_scores.append(np.mean(cross_val_score(pca, X)))\n        print(\"Done for\", n, \"features\")\n    return pca_scores\n\npca_scores = compute_scores(test_data)\nn_components_pca = np.argmax(pca_scores)\n\n# Plot results\nplt.figure(figsize=(10, 10))\nn_components = np.arange(1, len(features), 1)  # options for n_components\nplt.plot(n_components, pca_scores, 'b', label='PCA scores', linewidth=2)\nplt.axvline(n_components_pca, color='r', label='PCA CV: %d' % n_components_pca, linestyle='-', linewidth=2)\nplt.xlabel('Nr. of components')\nplt.ylabel('CV scores')\nplt.legend(loc='lower right')\nplt.show()\n\n# Plot Variance \npca = PCA(svd_solver='full')\nscaler = StandardScaler() \npipeline = make_pipeline(scaler, pca) \npipeline.fit(test_data)\npca_features = range(pca.n_components_) \nplt.figure(figsize=(30, 10)) \nplt.bar(pca_features, pca.explained_variance_) \nplt.xlabel('PCA - All features') \nplt.ylabel('variance') \nplt.xticks(pca_features) \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scale data\nscaler = preprocessing.MinMaxScaler()\ncombined_data = pd.concat([X_train, X_validation, test_data])\nscaler.fit(combined_data)\nX_train = pd.DataFrame(scaler.transform(X_train), columns=features)\nX_validation = pd.DataFrame(scaler.transform(X_validation), columns=features)\ntest_data = pd.DataFrame(scaler.transform(test_data), columns=features)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Understand the data\nprint(\"Nr of features:\", len(train_data.columns))\nprint(\"Train data:\", X_train.shape)\nprint(\"Validation data:\", X_validation.shape)\nprint(\"Test data:\", test_data.shape)\nprint()\n\nprint(\"Features information:\")\nprint()\nX_train.info()\n\nX_train.describe()\n\n# for feature in features:\n#     print(feature)\n#     print(X_train[feature].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature correlation\n\n# corr_matrix = X_train.corr(method='pearson')\n# # corr_matrix = train_data_no_missing_data.corr(method='spearman')\n# # corr_matrix = train_data_no_missing_data.corr(method='kendall')\n\n# # Top correlations\n# correlations = corr_matrix.abs().unstack().sort_values(kind='quicksort', ascending=False)\n# correlations = correlations[(correlations>0.40) & (correlations<1.0)]\n# print(correlations.head(15))\n\n# # Plot cluster map\n# sb.set(font_scale = 2)\n# cmap = sb.diverging_palette(h_neg=210, h_pos=350, s=90, l=30, as_cmap=True)\n# sb.clustermap(data=corr_matrix, figsize=(30, 30), annot=True, cmap = 'coolwarm')\n# # plt.savefig('clustermap.pdf')  Optional: save cluster map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build classifiers\n# https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n# XGBoost: https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html\n# XGBoost handling imbalanced datasets: https://machinelearningmastery.com/xgboost-for-imbalanced-classification/\n# LightGBM: https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n# Catboost https://towardsdatascience.com/https-medium-com-talperetz24-mastering-the-new-generation-of-gradient-boosting-db04062a7ea2\n# CatBoost vs LightGBM vs XGBoost: https://towardsdatascience.com/catboost-vs-light-gbm-vs-xgboost-5f93620723db\n# CatBoost examples + export to CoreML: https://catboost.ai/docs/concepts/python-usages-examples.html\nclassifiers = {\n\n    # Top classifier\n    \"Best Classifier\": XGBRegressor(eval_metric='auc', nthread=-1, random_state=42,\n                                    tree_method='gpu_hist',\n                                    n_estimators=1900,\n                                    learning_rate=0.01,\n                                    max_depth=6,\n#                                     scale_pos_weight=9.3,\n#                                     subsample=0.8,\n#                                     colsample_bytree= 0.3,\n#                                     reg_alpha=0.5,\n#                                     reg_lambda=4.5,\n                                    objective='reg:logistic'),\n    \n    # Good classifiers\n#     \"XGBoost 1\": XGBRegressor(eval_metric='auc', nthread=-1, random_state=42,\n#                             tree_method='gpu_hist',\n#                             n_estimators=500,\n#                             learning_rate=0.1,\n#                             max_depth=10,\n#                             subsample=0.4,\n#                             objective='reg:logistic'),\n    \n#     \"Baseline XGBoost\": XGBRegressor(eval_metric='auc', nthread=-1, random_state=42),\n    \n#     \"CatBoost\": CatBoostRegressor(eval_metric='AUC', thread_count=-1, silent=True, random_state=42,\n#                                   task_type=\"GPU\",\n#                                   iterations=5000,\n# #                                   n_estimators=1500,\n#                                   learning_rate=0.01,\n#                                   max_depth=6),\n    \n#     \"CatBoost\": CatBoostRegressor(silent=True, random_state=42,\n#                                   task_type=\"GPU\",\n#                                   iterations=5000,\n#                                   learning_rate=0.001,\n#                                   max_depth=15,\n#                                   eval_metric='AUC'),\n    \n#     \"CatBoost\": CatBoostRegressor(silent=True, random_state=42,\n#                                   task_type=\"GPU\",\n#                                   learning_rate=0.01,\n#                                   iterations=5000,\n#                                   eval_metric='AUC'),\n    \n    # Good classifiers\n#     \"SGBR\": GradientBoostingRegressor(max_depth=5, subsample=0.9, max_features=0.75, n_estimators=200),\n#     \"GBR\": GradientBoostingRegressor(n_estimators=20, min_samples_split=4, max_depth=60, random_state=42),\n#     \"AdaBoost\": AdaBoostClassifier(n_estimators=200),\n#     \"Bagging Classifier\": BaggingClassifier(),\n#     \"Random Forest\": RandomForestClassifier(max_depth=4, random_state=42),\n    \n    # Other classifiers\n#     \"Decision Tree\": DecisionTreeClassifier(max_depth=5),\n#     \"Naive Bayes\": GaussianNB(),\n#     \"Gaussian Process\": GaussianProcessClassifier(1.0 * RBF(1.0)),\n#     \"Neural Net\": MLPClassifier(alpha=1, max_iter=1000),\n#     \"QDA\": QuadraticDiscriminantAnalysis()\n    \n    # Very long wait time\n#     \"Nearest Neighbors\": KNeighborsClassifier(5),\n#     \"Linear SVM\": SVC(kernel=\"linear\", C=0.025),\n#     \"RBF SVM\": SVC(gamma=2, C=1),\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Parameter search\n# param_dist = {\n# #               'n_estimators': [1600,1700,1800,1900,2000],\n#               'colsample_bytree': [0.2,0.3,0.4],\n# #               'subsample': [0.6,0.8,1]\n# #                 'max_depth': [4,5,6],\n                \n# }\n\n# clf = XGBRegressor(eval_metric='auc', nthread=-1, random_state=42,\n#                    tree_method='gpu_hist',\n#                    n_estimators=1900,\n#                    learning_rate=0.01,\n#                    max_depth=6,\n#                    scale_pos_weight=9.3,\n#                    subsample=0.8,\n# #                  colsample_bytree= 0.3,\n# #                                     subsample=1,\n# #                                     reg_alpha=0.5,\n# #                                     reg_lambda=4.5,\n#                    objective='reg:logistic')\n\n# kfold = StratifiedKFold(n_splits=3, random_state=None, shuffle=True)\n# clf = RandomizedSearchCV(clf, \n#                          param_distributions = param_dist,\n#                          cv = kfold,\n#                          n_iter = 10,\n#                          scoring = 'roc_auc',\n#                          error_score = 0,\n#                          verbose = 3,\n#                          n_jobs = -1)\n# clf.fit(X_train, y_train)\n# print(clf.best_params_)\n# print(clf.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train classifiers\ndef fit(name, classifier, X_train, y_train):\n#     classifier.fit(X_train, y_train, sample_weight=sample_weight_train, early_stopping_rounds=20, eval_set=[(X_validation, y_validation)], verbose=False)\n    if isinstance(classifier, CatBoostRegressor):\n        cat_feature_ids = [1,2,3,4,6,7,8,9,10,12,13,14,15,16,17,18,19]   \n        # cat_features must be int or string\n        lst = list(X_train)\n        X_train[lst] = X_train[lst].astype(str)\n        X_validation[lst] = X_validation[lst].astype(str)\n        test_data[lst] = test_data[lst].astype(str)\n        classifier.fit(X_train, y_train, sample_weight=sample_weight_train, cat_features=cat_feature_ids, verbose=True)\n    else:\n        classifier.fit(X_train, y_train, sample_weight=sample_weight_train, verbose=True)\n\nfor index, (name, classifier) in enumerate(classifiers.items()):\n    print(\"Training classifier:\", name)\n    start_time = time.time()\n    fit(name, classifier, X_train, y_train)\n    print(\"Done training:\", time.time() - start_time, \"s\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict test results\ntest_predictions = { }\ndef predict(classifier, X_validation):\n    return classifier.predict(X_validation)\n#     return classifier.predict(X_validation, ntree_limit=classifier.best_ntree_limit)\n\nfor index, (name, classifier) in enumerate(classifiers.items()):\n    print(\"Predicting results using: \", name)\n    start_time = time.time()\n    test_predictions[name] = predict(classifier, X_validation)\n    print(\"Done predicting:\", time.time() - start_time, \"s\")\n    \n# Select the classifier\nselected_classifier = \"Best Classifier\"\nprint(\"Selected Classifier:\", selected_classifier)\nmodel = classifiers[selected_classifier]    \ntest_prediction = test_predictions[selected_classifier]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot ROC curve\n# Retrieve best Threshold\n# Threshold: https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/\n\n# Best Classifier - ROC Curve with k-Fold CV\ntprs = []\naucs = []\nthresholds = []\ncv = StratifiedKFold(n_splits=3)\nx = X_validation\ny = y_validation\nmean_fpr = np.linspace(0,1,100)\n\nplt.figure(figsize=(10, 10))\nfor i, (train, test) in enumerate(cv.split(x,y)):\n    print(\"Fold:\", i)\n    prediction = model.predict(x.iloc[test])\n    fpr, tpr, t = roc_curve(y.iloc[test], prediction)\n    roc_auc = auc(fpr, tpr)\n    plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n\n    tprs.append(np.interp(mean_fpr, fpr, tpr))\n    aucs.append(roc_auc)\n    gmeans = sqrt(tpr * (1-fpr))\n    ix = argmax(gmeans)\n    threshold = t[ix]\n    thresholds.append(threshold)\n    \nplt.plot([0,1],[0,1], 'r', linewidth=4)\nmean_tpr = np.mean(tprs, axis=0)\nmean_auc = auc(mean_fpr, mean_tpr) # Plor mean auc\nplt.plot(mean_fpr, mean_tpr, color='blue', label=r'Mean ROC (AUC = %0.2f )' % (mean_auc),lw=2, alpha=1)\nplt.xlabel('False Positive Rate', fontsize=16, color='white')\nplt.ylabel('True Positive Rate', fontsize=16, color='white')\nplt.title('ROC')\nplt.legend(loc=\"lower right\")\nplt.tick_params(axis='x', colors='white')\nplt.tick_params(axis='y', colors='white')\nplt.style.use('dark_background')\nplt.show()\n    \n# Compare all classifiers\n# labels = [\"Baseline\"]\n# plt.figure(figsize=(10,10))\n# plt.plot([0, 1], [0, 1], 'r', linewidth=4)\n# for index, (name, classifier) in enumerate(classifiers.items()): \n#     labels.append(name)\n#     false_positive_rate, true_positive_rate, thresholds = roc_curve(y_validation, test_predictions[name])\n#     plt.plot(false_positive_rate, true_positive_rate, linewidth=2)\n# plt.axis([0, 1, 0, 1])\n# plt.xlabel('False Positive Rate (FPR)', fontsize=16, color='white')\n# plt.ylabel('True Positive Rate (TPR)', fontsize=16, color='white')\n# plt.tick_params(axis='x', colors='white')\n# plt.tick_params(axis='y', colors='white')\n# plt.style.use('dark_background')\n# plt.legend(labels=labels)\n# plt.show()\n\n# Select best threshold\nprint(\"CV All thresholds\", thresholds)\nmean_cv_threshold = np.mean(thresholds)\nprint(\"CV Mean threshold\", mean_cv_threshold)\nfpr, tpr, non_cv_thresholds = roc_curve(y_validation, test_prediction)\ngmeans = sqrt(tpr * (1-fpr))\nix = argmax(gmeans)\nnon_cv_threshold = non_cv_thresholds[ix]\nprint('Non CV threshold=%f, G-Mean=%.3f' % (non_cv_threshold, gmeans[ix]))\nbest_threshold = non_cv_threshold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ROC AUC score, MAE, MSE, classification report\n# Precision: Number of true positives out of all predicted positive values\n# Recall: Find all positive values\n\nfor index, (name, y_pred) in enumerate(test_predictions.items()):\n    predictions = np.where(y_pred < best_threshold, 0, 1)\n    print(name, \n          \"Score: {0:.2f}\".format(metrics.roc_auc_score(y_validation, predictions)),\n          \"MAE: {0:.2f}\".format(mean_absolute_error(y_validation, predictions)),\n          \"MSE: {0:.2f}\".format(mean_squared_error(y_validation, predictions)))\n    print()\n    print(classification_report(y_validation, predictions))\n    print()\n    \n# Best result\n# Best Classifier Score: 0.88 MAE: 0.13 MSE: 0.13\n\n#               precision    recall  f1-score   support\n\n#            0       0.99      0.87      0.93     36230\n#            1       0.32      0.89      0.47      2476\n\n#     accuracy                           0.87     38706\n#    macro avg       0.65      0.88      0.70     38706\n# weighted avg       0.95      0.87      0.90     38706","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion matrix.\ntry:\n    predictions = np.where(test_predictions[selected_classifier] < best_threshold, 0, 1)\n    print(confusion_matrix(y_validation, predictions))\nexcept:\n    print(\"Could not show confusion matrix\")\n    \n# Previous best\n# [[31484  4746]\n#  [  279  2197]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Cross validation\n# figure = plt.figure(num=len(classifiers), figsize=(15, 60))\n# i = 1\n                  \n# for index, (name, classifier) in enumerate(classifiers.items()): \n#     print(name)\n    \n#     # CV score\n#     cv_score = cross_val_score(classifier, X_validation, y_validation, cv=3, scoring='roc_auc', n_jobs=-1, verbose=2) \n#     print('Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g' % (np.mean(cv_score), np.std(cv_score), np.min(cv_score), np.max(cv_score)))\n\n# #     if name != 'GridSearchCV' and name != 'Nearest Neighbors':\n# #         plt.subplot(len(classifiers), 1, i)\n\n# #         feat_imp = pd.Series(classifier.feature_importances_, features).sort_values(ascending=False)\n# #         print(feat_imp)\n# #         print()\n\n# #         ax = feat_imp.plot(kind='bar', title=name)\n# #         ax.set_title(name, fontsize=12, color='white')\n# #         i += 1\n   \n# # if name != 'GridSearchCV' and name != 'Nearest Neighbors':\n# #     plt.subplot(len(classifiers), 1, i)\n\n# #     feat_imp = pd.Series(classifier.feature_importances_, features).sort_values(ascending=False)\n# #     print(feat_imp)\n# #     print()\n\n# #     ax = feat_imp.plot(kind='bar', title=name)\n# #     ax.set_title(name, fontsize=12, color='white')\n# #     i += 1         \n    \n# # plt.style.use('dark_background')\n# # plt.tight_layout()\n# # # plt.savefig('feature_importances.pdf')  # Optional: save feature importances\n# # plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Vizualize classifier results - select two criterias\n# first_criteria_name = \"capital gains loss\"\n# second_criteria_name = \"weeks worked in year\"\n# first_criteria = X_validation[first_criteria_name]\n# second_criteria = X_validation[second_criteria_name]\n\n# # Plot configuration\n# figure = plt.figure(num=len(classifiers),figsize=(15, 15))\n# h = .02  # step size in the mesh\n# i = 1\n# subplotRows = 3\n\n# # Used to set the coordinates of each plot\n# x_min, x_max = first_criteria.min() - .1, first_criteria.max() + .1\n# y_min, y_max = second_criteria.min() - .1, second_criteria.max() + .1\n# xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n\n# cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n# ax = plt.subplot(subplotRows, len(classifiers) / subplotRows + 1, i)\n# ax.set_title(\"Input data\", fontsize=16, color='white')\n# ax.set_xlim(xx.min(), xx.max())\n# ax.set_ylim(yy.min(), yy.max())\n# ax.tick_params(axis='x', colors='white')\n# ax.tick_params(axis='y', colors='white')\n# ax.set_xlabel(first_criteria_name, fontsize=16, color='white')\n# ax.set_ylabel(second_criteria_name, fontsize=16, color='white')\n    \n# # Display test data\n# ax.scatter(first_criteria, second_criteria, c=y_validation, edgecolors='none', cmap=cm_bright)\n\n# i += 1\n\n# for index, (name, y_pred) in enumerate(test_predictions.items()):\n#     ax = plt.subplot(subplotRows, len(classifiers) / subplotRows + 1, i)\n#     ax.set_title(name, fontsize=16, color='white')\n\n#     # Display test data\n#     ax.scatter(first_criteria, second_criteria, c=y_pred, edgecolors='none', cmap=cm_bright)\n    \n#     # Display accuracy for the current classifier\n#     accuracy = classifiers[name].score(X_validation, y_validation)\n#     ax.text(xx.max() - 0.1, yy.min() - 0.1,\n#             \"{0:.2f}\".format(accuracy), \n#             size = 15, \n#             horizontalalignment='right')\n    \n#     ax.set_xlim(xx.min(), xx.max())\n#     ax.set_ylim(yy.min(), yy.max())\n#     ax.tick_params(axis='x', colors='white')\n#     ax.tick_params(axis='y', colors='white')\n#     ax.set_xlabel(first_criteria_name, fontsize=16, color='white')\n#     ax.set_ylabel(second_criteria_name, fontsize=16, color='white')\n    \n#     i += 1\n\n# plt.tight_layout()\n# plt.style.use('dark_background')\n# # plt.savefig('classifier_comparison.pdf') # Optioanl: save the plot\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature importance\ntry:\n    importances = pd.DataFrame({'feature':features, 'importance': np.round(model.feature_importances_, 3)})\n    importances = importances.sort_values('importance', ascending=False).set_index('feature')\n    print(importances)\nexcept:\n    print(\"Could not retrieve feature importances.\")\n    \n# Best features\n# is highly educated                    0.248\n# weeks worked in year                  0.173\n# sex                                   0.093\n# detailed occupation code              0.081\n# dividends from stocks                 0.063\n# capital gains loss                    0.060\n# age                                   0.043\n# education                             0.034\n# num persons worked for employer       0.031\n# marital status                        0.028\n# tax filer stat                        0.027\n# class of worker                       0.023\n# detailed industry code                0.018\n# wage per hour                         0.017\n# veterans benefits                     0.013\n# race                                  0.012\n# reason for unemployment               0.009\n# migration code-change in msa          0.009\n# lived in this house 1 year ago        0.009\n# citizenship                           0.008","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Validate model\n# # https://medium.com/all-things-ai/in-depth-parameter-tuning-for-random-forest-d67bb7e920d\n# params_list = [4, 6, 8]\n# # RMSE, MultiRMSE, MAE, Quantile, LogLinQuantile, Poisson, MAPE, Lq\n# train_results = []\n# test_results = []\n# for param in params_list:\n#     clf = XGBRegressor(eval_metric='auc', nthread=-1, random_state=42,\n#                        tree_method='gpu_hist',\n#                        n_estimators=5000,\n#                        learning_rate=0.01,\n#                        max_depth=param,\n# #                      gamma=param, min_child_weight=param,  # Does not affect results\n# #                        colsample_bytree=0.8,\n# #                        subsample=1,\n# #                        reg_alpha=0.5,\n# #                        reg_lambda=4.5,\n#                        objective='reg:logistic')\n\n# #     cat_features_names = X_train.columns\n# #     cat_features = [X_train.columns.get_loc(col) for col in cat_features_names]\n# #     clf = CatBoostRegressor(silent=True, random_state=42,\n# #                             task_type=\"GPU\",\n# #                             iterations=1500\n# #                             learning_rate=0.01,\n# #                             max_depth=8,\n# #                             eval_metric='AUC')    \n    \n#     start_time = time.time()\n        \n#     # Training dataset results\n# #     clf.fit(X_train, y_train, sample_weight=sample_weight_train, early_stopping_rounds=20, eval_set=[(X_validation, y_validation)], verbose=False)\n# #     train_pred = clf.predict(X_train, ntree_limit=clf.best_ntree_limit)\n#     clf.fit(X_train, y_train, sample_weight=sample_weight_train, verbose=False)\n#     train_pred = clf.predict(X_train)\n#     false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n#     roc_auc = auc(false_positive_rate, true_positive_rate)\n#     train_results.append(roc_auc)\n    \n#     # Validation dataset results\n#     y_pred = clf.predict(X_validation)\n#     false_positive_rate, true_positive_rate, thresholds = roc_curve(y_validation, y_pred)\n#     roc_auc = auc(false_positive_rate, true_positive_rate)\n#     test_results.append(roc_auc)\n    \n#     print(\"Done predicting using:\", param, \"Duration:\", time.time() - start_time, \"s\")\n    \n# figure = plt.figure(figsize=(10, 10))\n# line1, = plt.plot(params_list, train_results, 'b', label='Train AUC')\n# line2, = plt.plot(params_list, test_results, 'r', label='Test AUC')\n\n# plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n# plt.ylabel('AUC score')\n# plt.xlabel('Params')\n# plt.savefig('auc_nr_estimators.pdf')  # Optional: save result\n\n# print(\"Best accuracy:\", max(test_results))\n# assert max(test_results) > 0.95, \"Model is not an improvement\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Classify test data\npredictions = predict(classifiers[selected_classifier], test_data)\nif isinstance(classifier, CatBoostRegressor) or isinstance(classifier, XGBRegressor) or isinstance(classifier, GradientBoostingRegressor):\n    predictions = np.where(predictions < best_threshold, 0, 1)\n    \n# Predictions\n# Dataset probability for the label '- 50000' : 93.80%\n# Dataset probability for the label '50000+' : 6.20%\nnr_class_0 = len(predictions[predictions == 0])\nnr_class_1 = len(predictions[predictions == 1])\nprint(\"Class 0:\", nr_class_0, \"- {0:.2f}%\".format(nr_class_0 / len(predictions)))\nprint(\"Class 1:\", nr_class_1, \" - {0:.2f}%\".format(nr_class_1 / len(predictions)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Submit results\noutput = pd.DataFrame({'index': test_data.index, 'income class': predictions})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}